# Narwhal 与 Tusk 工作机制详解
本文档提出的 **Narwhal**（基于DAG的内存池协议）和 **Tusk**（异步共识协议）是一套专为高性能拜占庭容错（BFT）系统设计的解决方案，核心是将“交易可靠传播”与“交易排序”解耦，突破传统共识协议的性能瓶颈。以下分别从设计目标、核心机制、关键特性和工作流程四方面，详细拆解两者的工作原理。


## 一、Narwhal：基于DAG的高吞吐内存池
Narwhal 的定位是**高性能交易传播与存储层**，专注于在异步网络和节点故障下，实现交易的高吞吐可靠传播、因果关系维护，同时支持横向扩展。它将传统共识协议中“交易传播”的重活剥离，让共识层仅需处理轻量级的元数据（如区块哈希），从而提升整体系统性能。


### 1. 核心设计目标
- **解耦传播与排序**：交易的可靠传播由 Narwhal 负责，共识层（如 HotStuff）仅需对交易的“引用”（哈希）排序，避免共识层因处理大块交易数据成为瓶颈。
- **异步网络兼容**：容忍无界的消息延迟和有限的消息丢失，在网络不稳定时仍能维持高吞吐。
- **横向扩展**：支持每个验证节点部署多个“工作节点（Worker）”，通过并行处理提升吞吐量，且延迟不增加。
- **安全与可用性**：保证交易的完整性、因果一致性和抗审查性，即使部分节点故障，已提交的交易仍可被检索。


### 2. 核心数据结构：分层DAG（有向无环图）
Narwhal 的核心是**按轮次（Round）组织的分层DAG**，每个验证节点在每一轮生成一个“区块（Block）”，区块间通过引用形成因果关系，最终构成全局一致的交易因果历史。
- **区块结构**：每个区块包含三部分：
  1. **交易批量（Batch）**：一组用户提交的交易（或交易批量的哈希，用于扩展场景）。
  2. **引用列表**：包含上一轮（Round r-1）中至少 `2f+1` 个不同验证节点的区块“可用性证书（Certificate）”（`f` 为最大容错节点数，`2f+1` 确保超过半数诚实节点认可）。
  3. **签名**：区块创建者的数字签名，确保完整性。
- **DAG 分层逻辑**：
  - 每一轮（Round）为一个“层”，验证节点仅能引用上一轮的区块证书（避免循环依赖）。
  - 区块间的引用编码“因果关系”（记为 `b→b'`）：若区块 `b'` 引用了 `b` 的证书，则 `b` 一定在 `b'` 之前生成，`b` 中的交易需先于 `b'` 处理。


### 3. 关键机制
#### （1）轮次推进与区块生成
Narwhal 按“轮次”同步节点状态，确保DAG结构有序增长：
1. **初始轮次**：所有验证节点从 Round 0 开始，生成空区块并互相认证，作为DAG的“创世层”。
2. **轮次触发条件**：当一个验证节点收集到上一轮（Round r-1）中 `2f+1` 个不同节点的区块证书时，即可推进到 Round r。
3. **区块生成与广播**：节点在 Round r 生成新区块（包含本轮交易、上一轮 `2f+1` 个证书和自身签名），并通过“可靠广播”发送给其他节点。

#### （2）可用性证书（Certificate）机制
证书是 Narwhal 保证交易可用性的核心，确保“一旦区块被认证，所有诚实节点均可检索到该区块”：
1. **证书生成**：当一个节点收到其他节点的区块后，验证其合法性（签名有效、轮次正确、引用证书完整），若合法则返回“确认签名”；区块创建者收集到 `2f+1` 个确认签名后，将这些签名打包成“可用性证书”。
2. **证书传播**：区块创建者将证书广播给所有节点，其他节点将证书存入本地，用于下一轮区块的引用。
3. **安全性保障**：`2f+1` 个签名意味着至少 `f+1` 个诚实节点存储了该区块，即使 `f` 个节点故障，区块仍可通过诚实节点检索。

#### （3）可靠广播与拉取（Pull）优化
传统“推（Push）式”广播在节点故障时可能导致消息丢失，Narwhal 采用“推+拉”结合的可靠广播：
- **推送阶段**：区块创建者先主动将区块推送给所有节点，减少延迟。
- **拉取阶段**：若部分节点未收到区块，可通过“拉取”向已认证该区块的节点（即证书中的签名节点）请求数据。由于证书中至少包含 `f+1` 个诚实节点，拉取成功率接近100%，且仅需 `O(1)` 次请求。

#### （4）横向扩展：主-从（Primary-Worker）架构
为突破单节点的带宽/算力限制，Narwhal 支持每个验证节点部署多个 Worker：
- **Worker 角色**：负责接收用户交易、打包成“交易批量（Batch）”，并将批量的哈希发送给 Primary。
- **Primary 角色**：仅处理轻量级元数据——收集 Worker 的批量哈希，生成包含这些哈希的“主区块（Primary Block）”，并参与轮次推进和证书生成。
- **扩展效果**：吞吐量随 Worker 数量线性增长（如4个 Worker 可将吞吐量提升至单节点的4倍），且 Primary 因仅处理哈希，不会成为瓶颈。

#### （5）垃圾回收（Garbage Collection）
传统DAG协议因需维护全量历史导致存储膨胀，Narwhal 通过“共识层同步回收轮次”解决：
1. 共识层（如 HotStuff 或 Tusk）在排序交易时，同步约定“回收轮次”（如仅保留最近 `k` 轮的区块）。
2. 节点将超过回收轮次的区块离线存储（如存入CDN或分布式存储），本地仅保留当前轮次的区块和证书，内存占用稳定在 `O(n)`（`n` 为节点数）。
3. 未提交交易重注入：若某轮区块因故障未被排序，节点会将其中的交易重新打包到新轮次的区块中，避免交易丢失。


### 4. 工作流程总结
1. **交易接收**：用户将交易发送到验证节点的 Worker，Worker 打包成 Batch 并将哈希发送给 Primary。
2. **轮次推进**：Primary 收集上一轮 `2f+1` 个证书，推进到新轮次。
3. **区块与证书生成**：Primary 生成包含 Batch 哈希的主区块，广播给其他节点；收集 `2f+1` 个确认签名，生成可用性证书。
4. **DAG增长**：所有节点将新区块和证书加入本地DAG，用于下一轮引用。
5. **共识交互**：共识层（如 HotStuff）对DAG中的区块证书排序，排序后通过“因果读取（read_causal）”获取该证书对应的所有因果交易，完成最终提交。


## 二、Tusk：零消息开销的异步共识协议
Tusk 是基于 Narwhal DAG 的**异步共识协议**，核心目标是在完全异步网络（无消息延迟上限）和节点故障下，实现“零额外消息开销”的交易排序，同时保证低延迟和高吞吐。它解决了传统部分同步共识（如 HotStuff）在异步阶段“活锁”（吞吐量骤降）的问题。


### 1. 核心设计目标
- **完全异步兼容**：无需假设网络最终同步，即使消息延迟无界，仍能维持活锁（liveness）。
- **零消息开销**：仅复用 Narwhal 的DAG结构和消息，不额外发送共识消息（如投票、预提交），降低带宽消耗。
- **低延迟**：通过“波浪（Wave）划分”和“随机硬币”优化，在常见网络环境下（消息延迟随机分布）实现低延迟排序。
- **抗审查性**：依赖 Narwhal 的 `1/2-Chain Quality` 特性（至少一半区块由诚实节点生成），确保恶意节点无法 censorship 交易。


### 2. 核心思想：基于DAG的本地排序
Tusk 无需节点间额外通信，每个节点通过“本地解析DAG结构+随机硬币选举”即可独立完成交易排序，最终所有诚实节点的排序结果一致。核心是将DAG按“波浪（Wave）”划分，每波浪完成一次“ leader 选举与交易提交”。


### 3. 关键机制
#### （1）波浪（Wave）划分
Tusk 将 Narwhal 的连续轮次（Round）划分为“波浪”，每波浪包含 **3个连续轮次**，分别对应“提议-投票-随机选举”三个阶段：
- **Wave 的结构**：
  - 第1轮（提议阶段）：所有节点生成区块，包含本轮交易和上一轮证书（即 Narwhal 的常规区块），本质是“提议”待排序的交易。
  - 第2轮（投票阶段）：节点生成的区块需引用第1轮中至少 `2f+1` 个区块的证书，本质是“投票支持”第1轮的提议。
  - 第3轮（选举阶段）：节点在区块中嵌入“分布式随机硬币”的份额，所有节点收集这些份额生成“全局随机硬币”，用于选举第1轮的“ leader 区块”。
- **波浪重叠优化**：为减少延迟，Tusk 将前一个波浪的第3轮与后一个波浪的第1轮重叠（如 Wave 1 的第3轮 = Wave 2 的第1轮），使实际延迟从“3轮/波浪”降至“2轮/波浪”。

#### （2）分布式随机硬币
随机硬币是 Tusk 实现异步活锁的核心，确保“恶意节点无法提前预测 leader，避免针对性攻击”：
1. **硬币生成**：采用“门限签名（Threshold Signature）”机制，每个节点在第3轮区块中嵌入“硬币份额”（基于门限密钥的部分签名）；当收集到 `2f+1` 个份额时，即可合成“全局随机硬币”（一个随机数）。
2. **安全性**：门限签名确保需 `2f+1` 个节点参与才能生成硬币，恶意节点无法单独操控；且硬币在第3轮才生成，恶意节点无法提前知道 leader，无法在第1/2轮针对性破坏。

#### （3）Leader 选举与交易提交
每个波浪通过“随机硬币选举 leader 区块”，并基于 leader 完成交易排序：
1. **Leader 候选**：随机硬币生成后，根据硬币值从第1轮的区块中选择一个“候选 leader 区块”（如哈希值与硬币值最接近的区块）。
2. **提交条件**：若候选 leader 在第2轮中获得至少 `f+1` 个区块的引用（即 `f+1` 个节点“投票”支持该 leader），则该 leader 被“提交”。
3. **因果排序**：提交 leader 后，节点通过“read_causal”获取该 leader 的所有因果区块（即 `leader→b1→b2→…` 的所有区块），按“DAG拓扑序+确定性规则”（如区块生成时间）对这些区块的交易排序，完成最终提交。

#### （4）一致性保障：递归回溯机制
若不同节点因DAG视图差异导致“部分节点提交 leader，部分未提交”，Tusk 通过“递归回溯”确保最终一致：
1. 当节点 A 提交 Wave w 的 leader 后，会回溯到上一个已提交的 Wave w'（w' < w）。
2. 对 Wave w' 到 w 之间的每个波浪，检查“当前候选 leader 与已提交 leader 是否存在因果路径”（即是否有引用关系）。
3. 若存在路径，则将该候选 leader 纳入排序；若不存在，则重新通过随机硬币选举，直到所有波浪的 leader 形成连续因果链，确保所有诚实节点的排序结果一致。


### 4. 工作流程总结
1. **DAG复用**：Tusk 直接使用 Narwhal 生成的DAG，节点按轮次生成区块，无需额外消息。
2. **波浪划分**：将连续3轮划分为一个波浪，第1轮提议、第2轮投票、第3轮生成随机硬币。
3. **Leader 选举**：通过第3轮的全局随机硬币，从第1轮区块中选候选 leader，检查是否满足 `f+1` 个投票支持。
4. **交易排序**：提交 leader 后，递归回溯所有因果区块，按确定性规则排序交易。
5. **垃圾回收**：复用 Narwhal 的回收机制，仅保留当前波浪的区块，降低存储开销。


## 三、Narwhal 与 Tusk 的协同关系
Narwhal 与 Tusk 并非独立组件，而是“底层传播层+上层共识层”的深度协同：
- **Narwhal 为 Tusk 提供基础**：Narwhal 的DAG结构维护了交易的因果关系和可用性，Tusk 无需处理交易传播，仅需对DAG中的证书排序。
- **Tusk 为 Narwhal 提供共识保障**：Tusk 解决了 Narwhal DAG 的“最终排序”问题，确保所有诚实节点对交易的处理顺序一致。
- **性能协同**：Narwhal 的横向扩展能力（Worker 架构）可提升 Tusk 的吞吐量（如10个 Worker 可将 Tusk 吞吐量提升至60万 tx/sec），而 Tusk 的异步特性可避免 Narwhal 在网络不稳定时的活锁。


## 四、核心性能指标（WAN环境下）
| 协议         | 吞吐量（tx/sec） | 延迟（秒） | 故障下表现                |
|--------------|------------------|------------|---------------------------|
| Narwhal-HotStuff | 13万（单Worker） | <2         | 吞吐量稳定，延迟略有上升  |
| Narwhal-HotStuff（10 Worker） | 60万 | <2 | 吞吐量线性增长，延迟不变  |
| Tusk         | 16万（单Worker） | ~3         | 吞吐量稳定，延迟上升至6秒 |

综上，Narwhal 通过DAG和横向扩展解决了“交易传播瓶颈”，Tusk 通过异步共识和零消息开销解决了“排序活锁问题”，两者结合为高性能BFT系统提供了完整解决方案，可应用于区块链、分布式数据库等场景。